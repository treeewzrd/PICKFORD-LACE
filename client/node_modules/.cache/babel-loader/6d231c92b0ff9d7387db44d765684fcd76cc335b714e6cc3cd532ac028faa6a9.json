{"ast":null,"code":"import { Trie } from \"@wry/trie\";\nimport { StrongCache } from \"@wry/caches\";\nimport { Entry } from \"./entry.js\";\nimport { parentEntrySlot } from \"./context.js\";\n// These helper functions are important for making optimism work with\n// asynchronous code. In order to register parent-child dependencies,\n// optimism needs to know about any currently active parent computations.\n// In ordinary synchronous code, the parent context is implicit in the\n// execution stack, but asynchronous code requires some extra guidance in\n// order to propagate context from one async task segment to the next.\nexport { bindContext, noContext, nonReactive, setTimeout, asyncFromGen, Slot } from \"./context.js\";\n// A lighter-weight dependency, similar to OptimisticWrapperFunction, except\n// with only one argument, no makeCacheKey, no wrapped function to recompute,\n// and no result value. Useful for representing dependency leaves in the graph\n// of computation. Subscriptions are supported.\nexport { dep } from \"./dep.js\";\n// The defaultMakeCacheKey function is remarkably powerful, because it gives\n// a unique object for any shallow-identical list of arguments. If you need\n// to implement a custom makeCacheKey function, you may find it helpful to\n// delegate the final work to defaultMakeCacheKey, which is why we export it\n// here. However, you may want to avoid defaultMakeCacheKey if your runtime\n// does not support WeakMap, or you have the ability to return a string key.\n// In those cases, just write your own custom makeCacheKey functions.\nlet defaultKeyTrie;\nexport function defaultMakeCacheKey(...args) {\n  const trie = defaultKeyTrie || (defaultKeyTrie = new Trie(typeof WeakMap === \"function\"));\n  return trie.lookupArray(args);\n}\n// If you're paranoid about memory leaks, or you want to avoid using WeakMap\n// under the hood, but you still need the behavior of defaultMakeCacheKey,\n// import this constructor to create your own tries.\nexport { Trie as KeyTrie };\n;\nconst caches = new Set();\nexport function wrap(originalFunction, {\n  max = Math.pow(2, 16),\n  keyArgs,\n  makeCacheKey = defaultMakeCacheKey,\n  normalizeResult,\n  subscribe,\n  cache: cacheOption = StrongCache\n} = Object.create(null)) {\n  const cache = typeof cacheOption === \"function\" ? new cacheOption(max, entry => entry.dispose()) : cacheOption;\n  const optimistic = function () {\n    const key = makeCacheKey.apply(null, keyArgs ? keyArgs.apply(null, arguments) : arguments);\n    if (key === void 0) {\n      return originalFunction.apply(null, arguments);\n    }\n    let entry = cache.get(key);\n    if (!entry) {\n      cache.set(key, entry = new Entry(originalFunction));\n      entry.normalizeResult = normalizeResult;\n      entry.subscribe = subscribe;\n      // Give the Entry the ability to trigger cache.delete(key), even though\n      // the Entry itself does not know about key or cache.\n      entry.forget = () => cache.delete(key);\n    }\n    const value = entry.recompute(Array.prototype.slice.call(arguments));\n    // Move this entry to the front of the least-recently used queue,\n    // since we just finished computing its value.\n    cache.set(key, entry);\n    caches.add(cache);\n    // Clean up any excess entries in the cache, but only if there is no\n    // active parent entry, meaning we're not in the middle of a larger\n    // computation that might be flummoxed by the cleaning.\n    if (!parentEntrySlot.hasValue()) {\n      caches.forEach(cache => cache.clean());\n      caches.clear();\n    }\n    return value;\n  };\n  Object.defineProperty(optimistic, \"size\", {\n    get: () => cache.size,\n    configurable: false,\n    enumerable: false\n  });\n  Object.freeze(optimistic.options = {\n    max,\n    keyArgs,\n    makeCacheKey,\n    normalizeResult,\n    subscribe,\n    cache\n  });\n  function dirtyKey(key) {\n    const entry = key && cache.get(key);\n    if (entry) {\n      entry.setDirty();\n    }\n  }\n  optimistic.dirtyKey = dirtyKey;\n  optimistic.dirty = function dirty() {\n    dirtyKey(makeCacheKey.apply(null, arguments));\n  };\n  function peekKey(key) {\n    const entry = key && cache.get(key);\n    if (entry) {\n      return entry.peek();\n    }\n  }\n  optimistic.peekKey = peekKey;\n  optimistic.peek = function peek() {\n    return peekKey(makeCacheKey.apply(null, arguments));\n  };\n  function forgetKey(key) {\n    return key ? cache.delete(key) : false;\n  }\n  optimistic.forgetKey = forgetKey;\n  optimistic.forget = function forget() {\n    return forgetKey(makeCacheKey.apply(null, arguments));\n  };\n  optimistic.makeCacheKey = makeCacheKey;\n  optimistic.getKey = keyArgs ? function getKey() {\n    return makeCacheKey.apply(null, keyArgs.apply(null, arguments));\n  } : makeCacheKey;\n  return Object.freeze(optimistic);\n}","map":{"version":3,"names":["Trie","StrongCache","Entry","parentEntrySlot","bindContext","noContext","nonReactive","setTimeout","asyncFromGen","Slot","dep","defaultKeyTrie","defaultMakeCacheKey","args","trie","WeakMap","lookupArray","KeyTrie","caches","Set","wrap","originalFunction","max","Math","pow","keyArgs","makeCacheKey","normalizeResult","subscribe","cache","cacheOption","Object","create","entry","dispose","optimistic","key","apply","arguments","get","set","forget","delete","value","recompute","Array","prototype","slice","call","add","hasValue","forEach","clean","clear","defineProperty","size","configurable","enumerable","freeze","options","dirtyKey","setDirty","dirty","peekKey","peek","forgetKey","getKey"],"sources":["C:\\bootcamp\\PICKFORD---LACE\\client\\node_modules\\optimism\\src\\index.ts"],"sourcesContent":["import { Trie } from \"@wry/trie\";\r\n\r\nimport { StrongCache, CommonCache } from \"@wry/caches\";\r\nimport { Entry, AnyEntry } from \"./entry.js\";\r\nimport { parentEntrySlot } from \"./context.js\";\r\nimport type { NoInfer } from \"./helpers.js\";\r\n\r\n// These helper functions are important for making optimism work with\r\n// asynchronous code. In order to register parent-child dependencies,\r\n// optimism needs to know about any currently active parent computations.\r\n// In ordinary synchronous code, the parent context is implicit in the\r\n// execution stack, but asynchronous code requires some extra guidance in\r\n// order to propagate context from one async task segment to the next.\r\nexport {\r\n  bindContext,\r\n  noContext,\r\n  nonReactive,\r\n  setTimeout,\r\n  asyncFromGen,\r\n  Slot,\r\n} from \"./context.js\";\r\n\r\n// A lighter-weight dependency, similar to OptimisticWrapperFunction, except\r\n// with only one argument, no makeCacheKey, no wrapped function to recompute,\r\n// and no result value. Useful for representing dependency leaves in the graph\r\n// of computation. Subscriptions are supported.\r\nexport { dep, OptimisticDependencyFunction } from \"./dep.js\";\r\n\r\n// The defaultMakeCacheKey function is remarkably powerful, because it gives\r\n// a unique object for any shallow-identical list of arguments. If you need\r\n// to implement a custom makeCacheKey function, you may find it helpful to\r\n// delegate the final work to defaultMakeCacheKey, which is why we export it\r\n// here. However, you may want to avoid defaultMakeCacheKey if your runtime\r\n// does not support WeakMap, or you have the ability to return a string key.\r\n// In those cases, just write your own custom makeCacheKey functions.\r\nlet defaultKeyTrie: Trie<object> | undefined;\r\nexport function defaultMakeCacheKey(...args: any[]): object {\r\n  const trie = defaultKeyTrie || (\r\n    defaultKeyTrie = new Trie(typeof WeakMap === \"function\")\r\n  );\r\n  return trie.lookupArray(args);\r\n}\r\n\r\n// If you're paranoid about memory leaks, or you want to avoid using WeakMap\r\n// under the hood, but you still need the behavior of defaultMakeCacheKey,\r\n// import this constructor to create your own tries.\r\nexport { Trie as KeyTrie }\r\n\r\nexport type OptimisticWrapperFunction<\r\n  TArgs extends any[],\r\n  TResult,\r\n  TKeyArgs extends any[] = TArgs,\r\n  TCacheKey = any,\r\n> = ((...args: TArgs) => TResult) & {\r\n  // Get the current number of Entry objects in the LRU cache.\r\n  readonly size: number;\r\n\r\n  // Snapshot of wrap options used to create this wrapper function.\r\n  options: OptionsWithCacheInstance<TArgs, TKeyArgs, TCacheKey>;\r\n\r\n  // \"Dirty\" any cached Entry stored for the given arguments, marking that Entry\r\n  // and its ancestors as potentially needing to be recomputed. The .dirty(...)\r\n  // method of an optimistic function takes the same parameter types as the\r\n  // original function by default, unless a keyArgs function is configured, and\r\n  // then it matters that .dirty takes TKeyArgs instead of TArgs.\r\n  dirty: (...args: TKeyArgs) => void;\r\n  // A version of .dirty that accepts a key returned by .getKey.\r\n  dirtyKey: (key: TCacheKey | undefined) => void;\r\n\r\n  // Examine the current value without recomputing it.\r\n  peek: (...args: TKeyArgs) => TResult | undefined;\r\n  // A version of .peek that accepts a key returned by .getKey.\r\n  peekKey: (key: TCacheKey | undefined) => TResult | undefined;\r\n\r\n  // Completely remove the entry from the cache, dirtying any parent entries.\r\n  forget: (...args: TKeyArgs) => boolean;\r\n  // A version of .forget that accepts a key returned by .getKey.\r\n  forgetKey: (key: TCacheKey | undefined) => boolean;\r\n\r\n  // In order to use the -Key version of the above functions, you need a key\r\n  // rather than the arguments used to compute the key. These two functions take\r\n  // TArgs or TKeyArgs and return the corresponding TCacheKey. If no keyArgs\r\n  // function has been configured, TArgs will be the same as TKeyArgs, and thus\r\n  // getKey and makeCacheKey will be synonymous.\r\n  getKey: (...args: TArgs) => TCacheKey | undefined;\r\n\r\n  // This property is equivalent to the makeCacheKey function provided in the\r\n  // OptimisticWrapOptions, or (if no options.makeCacheKey function is provided)\r\n  // a default implementation of makeCacheKey. This function is also exposed as\r\n  // optimistic.options.makeCacheKey, somewhat redundantly.\r\n  makeCacheKey: (...args: TKeyArgs) => TCacheKey | undefined;\r\n};\r\n\r\nexport { CommonCache }\r\nexport interface CommonCacheConstructor<TCacheKey, TResult, TArgs extends any[]> extends Function {\r\n  new <K extends TCacheKey, V extends Entry<TArgs, TResult>>(max?: number, dispose?: (value: V, key?: K) => void): CommonCache<K,V>;\r\n}\r\n\r\nexport type OptimisticWrapOptions<\r\n  TArgs extends any[],\r\n  TKeyArgs extends any[] = TArgs,\r\n  TCacheKey = any,\r\n  TResult = any,\r\n> = {\r\n  // The maximum number of cache entries that should be retained before the\r\n  // cache begins evicting the oldest ones.\r\n  max?: number;\r\n  // Transform the raw arguments to some other type of array, which will then\r\n  // be passed to makeCacheKey.\r\n  keyArgs?: (...args: TArgs) => TKeyArgs;\r\n  // The makeCacheKey function takes the same arguments that were passed to\r\n  // the wrapper function and returns a single value that can be used as a key\r\n  // in a Map to identify the cached result.\r\n  makeCacheKey?: (...args: NoInfer<TKeyArgs>) => TCacheKey | undefined;\r\n  // Called when a new value is computed to allow efficient normalization of\r\n  // results over time, for example by returning older if equal(newer, older).\r\n  normalizeResult?: (newer: TResult, older: TResult) => TResult;\r\n  // If provided, the subscribe function should either return an unsubscribe\r\n  // function or return nothing.\r\n  subscribe?: (...args: TArgs) => void | (() => any);\r\n  cache?: CommonCache<NoInfer<TCacheKey>, Entry<NoInfer<TArgs>, NoInfer<TResult>>>\r\n    | CommonCacheConstructor<NoInfer<TCacheKey>, NoInfer<TResult>, NoInfer<TArgs>>;\r\n};\r\n\r\nexport interface OptionsWithCacheInstance<\r\n  TArgs extends any[],\r\n  TKeyArgs extends any[] = TArgs,\r\n  TCacheKey = any,\r\n  TResult = any,\r\n> extends OptimisticWrapOptions<TArgs, TKeyArgs, TCacheKey, TResult> {\r\n  cache: CommonCache<NoInfer<TCacheKey>, Entry<NoInfer<TArgs>, NoInfer<TResult>>>;\r\n};\r\n\r\nconst caches = new Set<CommonCache<any, AnyEntry>>();\r\n\r\nexport function wrap<\r\n  TArgs extends any[],\r\n  TResult,\r\n  TKeyArgs extends any[] = TArgs,\r\n  TCacheKey = any,\r\n>(originalFunction: (...args: TArgs) => TResult, {\r\n  max = Math.pow(2, 16),\r\n  keyArgs,\r\n  makeCacheKey = (defaultMakeCacheKey as () => TCacheKey),\r\n  normalizeResult,\r\n  subscribe,\r\n  cache: cacheOption = StrongCache,\r\n}: OptimisticWrapOptions<TArgs, TKeyArgs, TCacheKey, TResult> = Object.create(null)) {\r\n  const cache: CommonCache<TCacheKey, Entry<TArgs, TResult>> =\r\n    typeof cacheOption === \"function\"\r\n      ? new cacheOption(max, entry => entry.dispose())\r\n      : cacheOption;\r\n\r\n  const optimistic = function (): TResult {\r\n    const key = makeCacheKey.apply(\r\n      null,\r\n      keyArgs ? keyArgs.apply(null, arguments as any) : arguments as any\r\n    );\r\n\r\n    if (key === void 0) {\r\n      return originalFunction.apply(null, arguments as any);\r\n    }\r\n\r\n    let entry = cache.get(key)!;\r\n    if (!entry) {\r\n      cache.set(key, entry = new Entry(originalFunction));\r\n      entry.normalizeResult = normalizeResult;\r\n      entry.subscribe = subscribe;\r\n      // Give the Entry the ability to trigger cache.delete(key), even though\r\n      // the Entry itself does not know about key or cache.\r\n      entry.forget = () => cache.delete(key);\r\n    }\r\n\r\n    const value = entry.recompute(\r\n      Array.prototype.slice.call(arguments) as TArgs,\r\n    );\r\n\r\n    // Move this entry to the front of the least-recently used queue,\r\n    // since we just finished computing its value.\r\n    cache.set(key, entry);\r\n\r\n    caches.add(cache);\r\n\r\n    // Clean up any excess entries in the cache, but only if there is no\r\n    // active parent entry, meaning we're not in the middle of a larger\r\n    // computation that might be flummoxed by the cleaning.\r\n    if (! parentEntrySlot.hasValue()) {\r\n      caches.forEach(cache => cache.clean());\r\n      caches.clear();\r\n    }\r\n\r\n    return value;\r\n  } as OptimisticWrapperFunction<TArgs, TResult, TKeyArgs, TCacheKey>;\r\n\r\n  Object.defineProperty(optimistic, \"size\", {\r\n    get: () => cache.size,\r\n    configurable: false,\r\n    enumerable: false,\r\n  });\r\n\r\n  Object.freeze(optimistic.options = {\r\n    max,\r\n    keyArgs,\r\n    makeCacheKey,\r\n    normalizeResult,\r\n    subscribe,\r\n    cache,\r\n  });\r\n\r\n  function dirtyKey(key: TCacheKey | undefined) {\r\n    const entry = key && cache.get(key);\r\n    if (entry) {\r\n      entry.setDirty();\r\n    }\r\n  }\r\n  optimistic.dirtyKey = dirtyKey;\r\n  optimistic.dirty = function dirty() {\r\n    dirtyKey(makeCacheKey.apply(null, arguments as any));\r\n  };\r\n\r\n  function peekKey(key: TCacheKey | undefined) {\r\n    const entry = key && cache.get(key);\r\n    if (entry) {\r\n      return entry.peek();\r\n    }\r\n  }\r\n  optimistic.peekKey = peekKey;\r\n  optimistic.peek = function peek() {\r\n    return peekKey(makeCacheKey.apply(null, arguments as any));\r\n  };\r\n\r\n  function forgetKey(key: TCacheKey | undefined) {\r\n    return key ? cache.delete(key) : false;\r\n  }\r\n  optimistic.forgetKey = forgetKey;\r\n  optimistic.forget = function forget() {\r\n    return forgetKey(makeCacheKey.apply(null, arguments as any));\r\n  };\r\n\r\n  optimistic.makeCacheKey = makeCacheKey;\r\n  optimistic.getKey = keyArgs ? function getKey() {\r\n    return makeCacheKey.apply(null, keyArgs.apply(null, arguments as any));\r\n  } : makeCacheKey as (...args: any[]) => TCacheKey | undefined;\r\n\r\n  return Object.freeze(optimistic);\r\n}\r\n"],"mappings":"AAAA,SAASA,IAAI,QAAQ,WAAW;AAEhC,SAASC,WAAW,QAAqB,aAAa;AACtD,SAASC,KAAK,QAAkB,YAAY;AAC5C,SAASC,eAAe,QAAQ,cAAc;AAG9C;AACA;AACA;AACA;AACA;AACA;AACA,SACEC,WAAW,EACXC,SAAS,EACTC,WAAW,EACXC,UAAU,EACVC,YAAY,EACZC,IAAI,QACC,cAAc;AAErB;AACA;AACA;AACA;AACA,SAASC,GAAG,QAAsC,UAAU;AAE5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAIC,cAAwC;AAC5C,OAAM,SAAUC,mBAAmBA,CAAC,GAAGC,IAAW;EAChD,MAAMC,IAAI,GAAGH,cAAc,KACzBA,cAAc,GAAG,IAAIX,IAAI,CAAC,OAAOe,OAAO,KAAK,UAAU,CAAC,CACzD;EACD,OAAOD,IAAI,CAACE,WAAW,CAACH,IAAI,CAAC;AAC/B;AAEA;AACA;AACA;AACA,SAASb,IAAI,IAAIiB,OAAO;AAqFvB;AAED,MAAMC,MAAM,GAAG,IAAIC,GAAG,EAA8B;AAEpD,OAAM,SAAUC,IAAIA,CAKlBC,gBAA6C,EAAE;EAC/CC,GAAG,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC,EAAE,EAAE,CAAC;EACrBC,OAAO;EACPC,YAAY,GAAId,mBAAuC;EACvDe,eAAe;EACfC,SAAS;EACTC,KAAK,EAAEC,WAAW,GAAG7B;AAAW,IAC8B8B,MAAM,CAACC,MAAM,CAAC,IAAI,CAAC;EACjF,MAAMH,KAAK,GACT,OAAOC,WAAW,KAAK,UAAU,GAC7B,IAAIA,WAAW,CAACR,GAAG,EAAEW,KAAK,IAAIA,KAAK,CAACC,OAAO,EAAE,CAAC,GAC9CJ,WAAW;EAEjB,MAAMK,UAAU,GAAG,SAAAA,CAAA;IACjB,MAAMC,GAAG,GAAGV,YAAY,CAACW,KAAK,CAC5B,IAAI,EACJZ,OAAO,GAAGA,OAAO,CAACY,KAAK,CAAC,IAAI,EAAEC,SAAgB,CAAC,GAAGA,SAAgB,CACnE;IAED,IAAIF,GAAG,KAAK,KAAK,CAAC,EAAE;MAClB,OAAOf,gBAAgB,CAACgB,KAAK,CAAC,IAAI,EAAEC,SAAgB,CAAC;;IAGvD,IAAIL,KAAK,GAAGJ,KAAK,CAACU,GAAG,CAACH,GAAG,CAAE;IAC3B,IAAI,CAACH,KAAK,EAAE;MACVJ,KAAK,CAACW,GAAG,CAACJ,GAAG,EAAEH,KAAK,GAAG,IAAI/B,KAAK,CAACmB,gBAAgB,CAAC,CAAC;MACnDY,KAAK,CAACN,eAAe,GAAGA,eAAe;MACvCM,KAAK,CAACL,SAAS,GAAGA,SAAS;MAC3B;MACA;MACAK,KAAK,CAACQ,MAAM,GAAG,MAAMZ,KAAK,CAACa,MAAM,CAACN,GAAG,CAAC;;IAGxC,MAAMO,KAAK,GAAGV,KAAK,CAACW,SAAS,CAC3BC,KAAK,CAACC,SAAS,CAACC,KAAK,CAACC,IAAI,CAACV,SAAS,CAAU,CAC/C;IAED;IACA;IACAT,KAAK,CAACW,GAAG,CAACJ,GAAG,EAAEH,KAAK,CAAC;IAErBf,MAAM,CAAC+B,GAAG,CAACpB,KAAK,CAAC;IAEjB;IACA;IACA;IACA,IAAI,CAAE1B,eAAe,CAAC+C,QAAQ,EAAE,EAAE;MAChChC,MAAM,CAACiC,OAAO,CAACtB,KAAK,IAAIA,KAAK,CAACuB,KAAK,EAAE,CAAC;MACtClC,MAAM,CAACmC,KAAK,EAAE;;IAGhB,OAAOV,KAAK;EACd,CAAmE;EAEnEZ,MAAM,CAACuB,cAAc,CAACnB,UAAU,EAAE,MAAM,EAAE;IACxCI,GAAG,EAAEA,CAAA,KAAMV,KAAK,CAAC0B,IAAI;IACrBC,YAAY,EAAE,KAAK;IACnBC,UAAU,EAAE;GACb,CAAC;EAEF1B,MAAM,CAAC2B,MAAM,CAACvB,UAAU,CAACwB,OAAO,GAAG;IACjCrC,GAAG;IACHG,OAAO;IACPC,YAAY;IACZC,eAAe;IACfC,SAAS;IACTC;GACD,CAAC;EAEF,SAAS+B,QAAQA,CAACxB,GAA0B;IAC1C,MAAMH,KAAK,GAAGG,GAAG,IAAIP,KAAK,CAACU,GAAG,CAACH,GAAG,CAAC;IACnC,IAAIH,KAAK,EAAE;MACTA,KAAK,CAAC4B,QAAQ,EAAE;;EAEpB;EACA1B,UAAU,CAACyB,QAAQ,GAAGA,QAAQ;EAC9BzB,UAAU,CAAC2B,KAAK,GAAG,SAASA,KAAKA,CAAA;IAC/BF,QAAQ,CAAClC,YAAY,CAACW,KAAK,CAAC,IAAI,EAAEC,SAAgB,CAAC,CAAC;EACtD,CAAC;EAED,SAASyB,OAAOA,CAAC3B,GAA0B;IACzC,MAAMH,KAAK,GAAGG,GAAG,IAAIP,KAAK,CAACU,GAAG,CAACH,GAAG,CAAC;IACnC,IAAIH,KAAK,EAAE;MACT,OAAOA,KAAK,CAAC+B,IAAI,EAAE;;EAEvB;EACA7B,UAAU,CAAC4B,OAAO,GAAGA,OAAO;EAC5B5B,UAAU,CAAC6B,IAAI,GAAG,SAASA,IAAIA,CAAA;IAC7B,OAAOD,OAAO,CAACrC,YAAY,CAACW,KAAK,CAAC,IAAI,EAAEC,SAAgB,CAAC,CAAC;EAC5D,CAAC;EAED,SAAS2B,SAASA,CAAC7B,GAA0B;IAC3C,OAAOA,GAAG,GAAGP,KAAK,CAACa,MAAM,CAACN,GAAG,CAAC,GAAG,KAAK;EACxC;EACAD,UAAU,CAAC8B,SAAS,GAAGA,SAAS;EAChC9B,UAAU,CAACM,MAAM,GAAG,SAASA,MAAMA,CAAA;IACjC,OAAOwB,SAAS,CAACvC,YAAY,CAACW,KAAK,CAAC,IAAI,EAAEC,SAAgB,CAAC,CAAC;EAC9D,CAAC;EAEDH,UAAU,CAACT,YAAY,GAAGA,YAAY;EACtCS,UAAU,CAAC+B,MAAM,GAAGzC,OAAO,GAAG,SAASyC,MAAMA,CAAA;IAC3C,OAAOxC,YAAY,CAACW,KAAK,CAAC,IAAI,EAAEZ,OAAO,CAACY,KAAK,CAAC,IAAI,EAAEC,SAAgB,CAAC,CAAC;EACxE,CAAC,GAAGZ,YAAyD;EAE7D,OAAOK,MAAM,CAAC2B,MAAM,CAACvB,UAAU,CAAC;AAClC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}